{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:09:49.292122Z",
     "iopub.status.busy": "2025-02-24T22:09:49.291735Z",
     "iopub.status.idle": "2025-02-24T22:48:55.077958Z",
     "shell.execute_reply": "2025-02-24T22:48:55.077111Z",
     "shell.execute_reply.started": "2025-02-24T22:09:49.292090Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n",
      "[nltk_data] Downloading package brown to /usr/share/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "Using device: cuda\n",
      "Vocabulary size: 13366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building co-occurrence matrix: 100%|██████████| 57340/57340 [00:47<00:00, 1200.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Truncated SVD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CBOW Data: 100%|██████████| 57340/57340 [00:04<00:00, 11771.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CBOW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 1.0654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.8738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.8310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.6975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 0.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 0.6211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 0.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 0.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 0.5391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 88.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 0.5212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 0.5045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1826/1826 [00:20<00:00, 89.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 0.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SkipGram Data: 100%|██████████| 57340/57340 [00:03<00:00, 15691.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SkipGram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 9655/9655 [01:32<00:00, 104.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 9655/9655 [01:32<00:00, 104.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 9655/9655 [01:32<00:00, 104.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 9655/9655 [01:32<00:00, 104.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 9655/9655 [01:32<00:00, 104.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 9655/9655 [01:32<00:00, 104.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 9655/9655 [01:32<00:00, 104.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 9655/9655 [01:32<00:00, 104.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 9655/9655 [01:32<00:00, 104.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 9655/9655 [01:32<00:00, 103.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 9655/9655 [01:32<00:00, 104.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 9655/9655 [01:31<00:00, 105.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 9655/9655 [01:32<00:00, 104.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 9655/9655 [01:33<00:00, 102.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 9655/9655 [01:34<00:00, 102.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 9655/9655 [01:33<00:00, 103.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 9655/9655 [01:33<00:00, 103.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 9655/9655 [01:33<00:00, 103.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 9655/9655 [01:33<00:00, 103.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 9655/9655 [01:32<00:00, 104.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9451\n",
      "SVD: Spearman ρ: 0.2408 | Valid pairs: 274/353\n",
      "CBOW: Spearman ρ: 0.3261 | Valid pairs: 274/353\n",
      "SkipGram: Spearman ρ: 0.4084 | Valid pairs: 274/353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-7a0e2d70d3ab>:345: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  skipgram_emb = torch.load('skipgram.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4083626589118093, 274)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# !pip install torch nltk pandas scipy numpy tqdm\n",
    "\n",
    "# Download Brown corpus\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.sparse.linalg import svds\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# CUDA setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ======================\n",
    "# 1. Preprocessing\n",
    "# ======================\n",
    "def preprocess_corpus(min_freq=5):  # Lowered from 10\n",
    "    sentences = brown.sents()\n",
    "    words = [word.lower() for sentence in sentences for word in sentence if word.isalpha()]\n",
    "    word_counts = Counter(words)\n",
    "    vocab = [word for word, count in word_counts.items() if count >= min_freq]\n",
    "    word2id = {word: i for i, word in enumerate(vocab)}\n",
    "    id2word = {i: word for word, i in word2id.items()}\n",
    "    return word2id, id2word, vocab\n",
    "\n",
    "word2id, id2word, vocab = preprocess_corpus()\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 200  # Increased from 100\n",
    "window_size = 3   # Increased from 3\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# ======================\n",
    "# 2. SVD with PMI\n",
    "# ======================\n",
    "def build_co_matrix():\n",
    "    matrix = lil_matrix((vocab_size, vocab_size), dtype=np.float32)\n",
    "    \n",
    "    for sentence in tqdm(brown.sents(), desc=\"Building co-occurrence matrix\"):\n",
    "        sentence = [word.lower() for word in sentence if word.isalpha()]\n",
    "        sentence_ids = [word2id[word] for word in sentence if word in word2id]\n",
    "        \n",
    "        for i in range(len(sentence_ids)):\n",
    "            target = sentence_ids[i]\n",
    "            context_ids = sentence_ids[max(0, i - window_size):i] + sentence_ids[i + 1:i + window_size + 1]\n",
    "\n",
    "            for j, ctx in enumerate(context_ids):\n",
    "                distance = abs(i - j)\n",
    "                weight = 1.0 / distance if distance > 0 else 1.0  # Inverse distance weighting\n",
    "                matrix[target, ctx] += weight\n",
    "\n",
    "    # Convert to CSR format before PMI calculations\n",
    "    matrix = matrix.tocsr()\n",
    "\n",
    "    # PMI calculation with epsilon to prevent division errors\n",
    "    row_sums = np.array(matrix.sum(axis=1)).flatten() + 1e-8\n",
    "    col_sums = np.array(matrix.sum(axis=0)).flatten() + 1e-8\n",
    "    total = matrix.sum()\n",
    "\n",
    "    matrix = matrix.multiply(total) / (row_sums[:, None] * col_sums[None, :])\n",
    "    matrix.data = np.log(np.maximum(matrix.data, 1e-8))  # Prevent negative logs\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# Compute SVD\n",
    "co_matrix = build_co_matrix()\n",
    "print(\"Computing Truncated SVD...\")\n",
    "\n",
    "U, S, Vt = svds(co_matrix, k=embed_dim)\n",
    "idx = np.argsort(-S)  # Sort in descending order\n",
    "S = S[idx]\n",
    "U = U[:, idx]\n",
    "\n",
    "# Convert to torch tensor and normalize embeddings\n",
    "svd_embeddings = torch.from_numpy(U).float()\n",
    "svd_embeddings = F.normalize(svd_embeddings, p=2, dim=1)\n",
    "\n",
    "# Save the embeddings\n",
    "torch.save(svd_embeddings, 'svd.pt')\n",
    "\n",
    "# ======================\n",
    "# 3. CBOW with Negative Sampling\n",
    "# ======================\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "word_freq = Counter()\n",
    "for sentence in brown.sents():\n",
    "    words = [word.lower() for word in sentence if word.isalpha()]\n",
    "    word_freq.update(words)\n",
    "\n",
    "# Convert to dictionary with word IDs\n",
    "word_freq = {word2id[word]: freq for word, freq in word_freq.items() if word in word2id}\n",
    "\n",
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        for sentence in tqdm(brown.sents(), desc=\"CBOW Data\"):\n",
    "            sentence = [word.lower() for word in sentence if word.isalpha()]\n",
    "            sentence_ids = [word2id[word] for word in sentence if word in word2id]\n",
    "            for i in range(len(sentence_ids)):\n",
    "                target = sentence_ids[i]\n",
    "                context = sentence_ids[max(0,i-window_size):i] + sentence_ids[i+1:i+window_size+1]\n",
    "                if context:\n",
    "                    self.data.append((context, target))\n",
    "\n",
    "    def __len__(self): return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        return torch.tensor(context), torch.tensor(target)\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, num_neg=25):\n",
    "        super().__init__()\n",
    "        self.in_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.out_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.in_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.out_emb.weight)\n",
    "\n",
    "        self.num_neg = num_neg\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        batch_size = targets.size(0)\n",
    "        \n",
    "        mask = (contexts != 0).unsqueeze(-1).float()\n",
    "        ctx_emb = (self.in_emb(contexts) * mask).mean(dim=1)\n",
    "\n",
    "        pos_scores = (self.out_emb(targets) * ctx_emb).sum(dim=-1)\n",
    "\n",
    "        # Negative samples\n",
    "        unigram_dist = torch.tensor([word_freq.get(i, 1e-5) ** 0.75 for i in range(vocab_size)], device=device)\n",
    "        unigram_dist /= unigram_dist.sum()\n",
    "    \n",
    "        noise = torch.multinomial(unigram_dist, batch_size * self.num_neg, replacement=True).view(batch_size, self.num_neg)\n",
    " \n",
    "        neg_scores = (self.out_emb(noise) * ctx_emb.unsqueeze(1)).sum(dim=-1)\n",
    "\n",
    "        pos_loss = F.logsigmoid(pos_scores).mean()\n",
    "        neg_loss = F.logsigmoid(-neg_scores).mean()\n",
    "        return -(pos_loss + neg_loss)\n",
    "\n",
    "# Optimized DataLoader\n",
    "def collate_cbow(batch):\n",
    "    contexts, targets = zip(*batch)\n",
    "    # Pad contexts to equal length\n",
    "    max_len = max(len(c) for c in contexts)\n",
    "    padded = [torch.cat([c, torch.zeros(max_len-len(c), dtype=torch.long)]) for c in contexts]\n",
    "    return torch.stack(padded), torch.stack(targets)\n",
    "\n",
    "# Training\n",
    "model = CBOW().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "dataset = CBOWDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True, \n",
    "                       collate_fn=collate_cbow, pin_memory=True,\n",
    "                       num_workers=os.cpu_count())\n",
    "\n",
    "print(\"\\nTraining CBOW...\")\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for contexts, targets in tqdm(dataloader):\n",
    "        contexts, targets = contexts.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(contexts, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Save embeddings (average input/output)\n",
    "cbow_emb = (model.in_emb.weight + model.out_emb.weight).cpu() / 2\n",
    "cbow_emb = ((model.in_emb.weight + model.out_emb.weight) / 2).detach().cpu()\n",
    "\n",
    "torch.save(cbow_emb, 'cbow.pt')\n",
    "\n",
    "# ======================\n",
    "# 4. Skip-Gram with Negative Sampling\n",
    "# ======================\n",
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        for sentence in tqdm(brown.sents(), desc=\"SkipGram Data\"):\n",
    "            sentence = [word.lower() for word in sentence if word.isalpha()]\n",
    "            sentence_ids = [word2id[word] for word in sentence if word in word2id]\n",
    "            self.data.extend(\n",
    "                (sentence_ids[i], ctx) \n",
    "                for i in range(len(sentence_ids)) \n",
    "                for ctx in (sentence_ids[max(0, i - window_size):i] + \n",
    "                            sentence_ids[i + 1: i + window_size + 1])\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target, context = self.data[idx]\n",
    "        return torch.tensor(target, dtype=torch.long), torch.tensor(context, dtype=torch.long)\n",
    "# Ensure vocab_size is correctly set to the size of word2id\n",
    "vocab_size = len(word2id) \n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.out_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        nn.init.xavier_uniform_(self.in_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.out_emb.weight)\n",
    "\n",
    "    def forward(self, targets, contexts, num_neg=25):\n",
    "        batch_size = targets.size(0)\n",
    "        target_emb = self.in_emb(targets)  # (batch_size, embed_dim)\n",
    "        \n",
    "        # Positive sample loss\n",
    "        pos_scores = (self.out_emb(contexts) * target_emb).sum(dim=1)\n",
    "        \n",
    "        # Negative samples using unigram distribution\n",
    "        unigram_dist = torch.tensor([word_freq.get(i, 1e-5) ** 0.75 for i in range(vocab_size)], device=targets.device)\n",
    "        unigram_dist /= unigram_dist.sum()\n",
    "        noise = torch.multinomial(unigram_dist, batch_size * num_neg, replacement=True).view(batch_size, num_neg)\n",
    "        \n",
    "        neg_scores = (self.out_emb(noise) * target_emb.unsqueeze(1)).sum(dim=2)\n",
    "\n",
    "        # NCE loss\n",
    "        pos_loss = F.logsigmoid(pos_scores).mean()\n",
    "        neg_loss = F.logsigmoid(-neg_scores).mean()\n",
    "        return -(pos_loss + neg_loss)\n",
    "\n",
    "# Initialize Model, Optimizer, and Dataloader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = SkipGram().to(device)\n",
    "model = SkipGram().to(device) \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "dataset = SkipGramDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Training Loop\n",
    "print(\"\\nTraining SkipGram...\")\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for target, context in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        target, context = target.to(device), context.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(target, context)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Loss: {total_loss / len(dataloader):.4f}\")  # Corrected loss normalization\n",
    "\n",
    "\n",
    "# Save embeddings (average input/output)\n",
    "skipgram_emb = (model.in_emb.weight + model.out_emb.weight) / 2\n",
    "skipgram_emb = F.normalize(skipgram_emb, p=2, dim=1).detach().cpu()\n",
    "torch.save(skipgram_emb, 'skipgram.pt')\n",
    "\n",
    "# ======================\n",
    "# 5. Evaluation\n",
    "# ======================\n",
    "def evaluate_model(embeddings, model_name):\n",
    "    if isinstance(embeddings, str):\n",
    "        embeddings = torch.load(embeddings)\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    df = pd.read_csv('/kaggle/input/wordsim353/wordsim353.csv')\n",
    "    valid_pairs = 0\n",
    "    human, model_scores = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        w1 = row['word1'].lower().strip()\n",
    "        w2 = row['word2'].lower().strip()\n",
    "        score = row['score'] if 'score' in row else row['Human (mean)']\n",
    "        \n",
    "        if w1 in word2id and w2 in word2id:\n",
    "            idx1, idx2 = word2id[w1], word2id[w2]\n",
    "            if idx1 < len(embeddings) and idx2 < len(embeddings):\n",
    "                vec1 = embeddings[idx1]\n",
    "                vec2 = embeddings[idx2]\n",
    "                cos_sim = torch.dot(vec1, vec2).item()\n",
    "                human.append(score)\n",
    "                model_scores.append(cos_sim)\n",
    "                valid_pairs += 1\n",
    "    \n",
    "    rho, _ = spearmanr(human, model_scores)\n",
    "    print(f\"{model_name}: Spearman ρ: {rho:.4f} | Valid pairs: {valid_pairs}/{len(df)}\")\n",
    "    return rho, valid_pairs  # <-- CRITICAL RETURN STATEMENT\n",
    "\n",
    "# Evaluate all models\n",
    "evaluate_model(svd_embeddings, \"SVD\")\n",
    "evaluate_model(cbow_emb, \"CBOW\")\n",
    "for word, idx in word2id.items():\n",
    "    if idx >= len(skipgram_emb):\n",
    "        print(f\"Error: '{word}' has index {idx} but embeddings only have size {len(skipgram_emb)}\")\n",
    "skipgram_emb = torch.load('skipgram.pt')\n",
    "evaluate_model(skipgram_emb, \"SkipGram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:51:08.955209Z",
     "iopub.status.busy": "2025-02-24T22:51:08.954869Z",
     "iopub.status.idle": "2025-02-24T22:51:09.096053Z",
     "shell.execute_reply": "2025-02-24T22:51:09.095124Z",
     "shell.execute_reply.started": "2025-02-24T22:51:08.955183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated svd_results.csv with 274 valid pairs\n",
      "Generated cbow_results.csv with 274 valid pairs\n",
      "Generated skipgram_results.csv with 274 valid pairs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def generate_wordsim_csv(embeddings, model_name, output_csv=\"wordsim_results.csv\"):\n",
    "    \"\"\"\n",
    "    Generate CSV with word pairs, cosine similarities, human scores, and Spearman correlation\n",
    "    embeddings: Torch tensor of word embeddings\n",
    "    model_name: Name of the model (e.g., \"SVD\", \"CBOW\")\n",
    "    output_csv: Output CSV filename\n",
    "    \"\"\"\n",
    "    # Normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    # Load WordSim-353 dataset\n",
    "    df = pd.read_csv('/kaggle/input/wordsim353/wordsim353.csv')\n",
    "    \n",
    "    # Prepare results container\n",
    "    results = []\n",
    "    valid_pairs = 0\n",
    "    \n",
    "    # Process each pair\n",
    "    for _, row in df.iterrows():\n",
    "        w1 = row['word1'].lower().strip()\n",
    "        w2 = row['word2'].lower().strip()\n",
    "        human_score = row.get('score', row.get('Human (mean)', 0))\n",
    "        \n",
    "        if w1 in word2id and w2 in word2id:\n",
    "            idx1, idx2 = word2id[w1], word2id[w2]\n",
    "            \n",
    "            if idx1 < embeddings.shape[0] and idx2 < embeddings.shape[0]:\n",
    "                vec1 = embeddings[idx1]\n",
    "                vec2 = embeddings[idx2]\n",
    "                cos_sim = torch.dot(vec1, vec2).item()\n",
    "                \n",
    "                results.append({\n",
    "                    'word1': w1,\n",
    "                    'word2': w2,\n",
    "                    'cosine_similarity': cos_sim,\n",
    "                    'human_score': human_score\n",
    "                })\n",
    "                valid_pairs += 1\n",
    "    \n",
    "    # Create DataFrame and calculate Spearman\n",
    "    results_df = pd.DataFrame(results)\n",
    "    if not results_df.empty:\n",
    "        rho, _ = spearmanr(results_df['cosine_similarity'], results_df['human_score'])\n",
    "        \n",
    "        # Add Spearman row\n",
    "        spearman_row = pd.DataFrame([{\n",
    "            'word1': '[Spearman Correlation]',\n",
    "            'word2': '',\n",
    "            'cosine_similarity': rho,\n",
    "            'human_score': ''\n",
    "        }])\n",
    "        \n",
    "        final_df = pd.concat([results_df, spearman_row], ignore_index=True)\n",
    "    else:\n",
    "        final_df = results_df\n",
    "    \n",
    "    # Save to CSV\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Generated {output_csv} with {valid_pairs} valid pairs\")\n",
    "    return final_df\n",
    "\n",
    "# Usage example\n",
    "svd_results = generate_wordsim_csv(svd_embeddings, \"SVD\", \"svd_results.csv\")\n",
    "cbow_results = generate_wordsim_csv(cbow_emb, \"CBOW\", \"cbow_results.csv\")\n",
    "skipgram_results = generate_wordsim_csv(skipgram_emb, \"SkipGram\", \"skipgram_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:51:19.308468Z",
     "iopub.status.busy": "2025-02-24T22:51:19.308155Z",
     "iopub.status.idle": "2025-02-24T22:51:19.317405Z",
     "shell.execute_reply": "2025-02-24T22:51:19.316362Z",
     "shell.execute_reply.started": "2025-02-24T22:51:19.308442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 13 (<ipython-input-4-3cf1ae73f853>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-3cf1ae73f853>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    epoch_loss = total_loss/len(dataloader)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 13\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================================\n",
    "# 1. Modify Training Loops to Record Losses\n",
    "# ===========================================\n",
    "\n",
    "# CBOW Training (modify existing loop)\n",
    "cbow_losses = []\n",
    "print(\"\\nTraining CBOW...\")\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for contexts, targets in tqdm(dataloader):\n",
    "        # ... existing training code ...\n",
    "        epoch_loss = total_loss/len(dataloader)\n",
    "        cbow_losses.append(epoch_loss)  # Record loss\n",
    "        print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Skip-Gram Training (modify existing loop)\n",
    "skipgram_losses = []\n",
    "print(\"\\nTraining SkipGram...\")\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for target, context in tqdm(dataloader):\n",
    "        # ... existing training code ...\n",
    "        epoch_loss = total_loss/len(dataloader)\n",
    "        skipgram_losses.append(epoch_loss)  # Record loss\n",
    "        print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# ===========================================\n",
    "# 2. Plot Training Curves\n",
    "# ===========================================\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# CBOW Loss Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(cbow_losses)+1), cbow_losses, 'b-o', linewidth=2)\n",
    "plt.title(\"CBOW Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Skip-Gram Loss Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(skipgram_losses)+1), skipgram_losses, 'r-s', linewidth=2)\n",
    "plt.title(\"Skip-Gram Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png')\n",
    "plt.close()\n",
    "\n",
    "# ===========================================\n",
    "# 3. Plot Spearman Comparison\n",
    "# ===========================================\n",
    "\n",
    "# Get Spearman scores from evaluation\n",
    "svd_rho = 0.42  # Replace with actual value from your evaluation\n",
    "cbow_rho = 0.58  # Replace with actual value\n",
    "skipgram_rho = 0.62  # Replace with actual value\n",
    "\n",
    "models = ['SVD', 'CBOW', 'Skip-Gram']\n",
    "scores = [svd_rho, cbow_rho, skipgram_rho]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(models, scores, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "\n",
    "plt.title(\"Spearman Rank Correlation Comparison\")\n",
    "plt.ylabel(\"Spearman ρ\")\n",
    "plt.ylim(0, 0.7)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2f}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig('spearman_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:51:54.530148Z",
     "iopub.status.busy": "2025-02-24T22:51:54.529845Z",
     "iopub.status.idle": "2025-02-24T22:51:54.921063Z",
     "shell.execute_reply": "2025-02-24T22:51:54.920206Z",
     "shell.execute_reply.started": "2025-02-24T22:51:54.530126Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-70f84238302f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  svd_emb = torch.load('svd.pt')\n",
      "<ipython-input-6-70f84238302f>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cbow_emb = torch.load('cbow.pt')\n",
      "<ipython-input-6-70f84238302f>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  skipgram_emb = torch.load('skipgram.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Spearman ρ: 0.2408 | Valid pairs: 274/353\n",
      "CBOW: Spearman ρ: 0.3261 | Valid pairs: 274/353\n",
      "SkipGram: Spearman ρ: 0.4084 | Valid pairs: 274/353\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "svd_emb = torch.load('svd.pt')\n",
    "cbow_emb = torch.load('cbow.pt')\n",
    "skipgram_emb = torch.load('skipgram.pt')\n",
    "\n",
    "# Get Spearman scores\n",
    "svd_rho, _ = evaluate_model(svd_emb, \"SVD\")\n",
    "cbow_rho, _ = evaluate_model(cbow_emb, \"CBOW\")\n",
    "skipgram_rho, _ = evaluate_model(skipgram_emb, \"SkipGram\")\n",
    "\n",
    "# Plot using the code from earlier\n",
    "models = ['SVD', 'CBOW', 'Skip-Gram']\n",
    "scores = [svd_rho, cbow_rho, skipgram_rho]\n",
    "plt.bar(models, scores)\n",
    "plt.savefig('spearman.png')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6724244,
     "sourceId": 10829204,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
